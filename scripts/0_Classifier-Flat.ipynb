{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "*Written by Viviane Clay*\n",
    "\n",
    "Classifies objects contained in images taken from the Obstacle Tower environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T12:56:02.900633Z",
     "start_time": "2021-01-08T12:55:37.825082Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vkakerbeck\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\vkakerbeck\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\vkakerbeck\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\vkakerbeck\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\vkakerbeck\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\vkakerbeck\\miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "import cv2\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.layers as c_layers\n",
    "import glob\n",
    "from scipy import misc\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "(Adapt file paths as needed)\n",
    "\n",
    "Training data can be found here: http://dx.doi.org/10.17632/zdh4d5ws2z.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-08T12:56:33.270582Z",
     "start_time": "2021-01-08T12:56:28.205122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34990 images belonging to 18 classes.\n",
      "Found 3879 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "all_classes = ['[0, 0, 0, 0]','[0, 0, 0, 1]','[0, 0, 1, 0]','[0, 1, 0, 0]','[0, 1, 1, 0]','[1, 0, 0, 0]',\n",
    "               '[1, 0, 1, 0]','[2, 0, 0, 0]','[2, 0, 0, 1]','[2, 0, 1, 0]','[2, 1, 0, 0]',#'[2, 1, 1, 0]','[2,0,1,1]'\n",
    "               '[3, 0, 0, 0]','[3, 0, 0, 1]','[3, 0, 1, 0]','[3, 1, 0, 0]','[4, 0, 0, 0]','[4, 0, 0, 1]',\n",
    "               '[4, 0, 1, 0]']\n",
    "datagen = ImageDataGenerator(validation_split=0.1,rescale=1./255)\n",
    "train_it = datagen.flow_from_directory('./Results/TowerTraining/Classifier/Sorted/', class_mode='sparse',\n",
    "                                       batch_size=256,shuffle=True,subset=\"training\",target_size=(168,168),classes=all_classes)\n",
    "val_it = datagen.flow_from_directory('./Results/TowerTraining/Classifier/Sorted/', class_mode='sparse',\n",
    "                                       batch_size=256,shuffle=True,subset=\"validation\",target_size=(168,168),classes=all_classes)\n",
    "\n",
    "realLabel = []\n",
    "for c,v in train_it.class_indices.items():\n",
    "    c_ext = np.fromstring(c[1:-1], dtype=int, sep=', ')\n",
    "    realLabel.append(c_ext)\n",
    "\n",
    "def getRealLabel(labelBatch,RL):\n",
    "    newLB = []\n",
    "    for label in labelBatch:\n",
    "        l = RL[int(label)]\n",
    "        newLB.append(l)\n",
    "    return newLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T10:26:28.888811Z",
     "start_time": "2020-09-11T10:26:28.301117Z"
    }
   },
   "outputs": [],
   "source": [
    "xVal,yVal = val_it.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T09:46:23.565219Z",
     "start_time": "2020-08-28T09:46:23.562225Z"
    }
   },
   "outputs": [],
   "source": [
    "yVal_r = getRealLabel(yVal,realLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:45:13.384174Z",
     "start_time": "2020-09-11T08:45:13.377193Z"
    }
   },
   "outputs": [],
   "source": [
    "def getFlatLabel(label2D):\n",
    "    flatLabels = []\n",
    "    for label in label2D:\n",
    "        flatLabel = np.zeros(8)\n",
    "        if label[0] == 0:\n",
    "            flatLabel[0] = 1\n",
    "        elif label[0] == 1:\n",
    "            flatLabel[1] = 1\n",
    "        elif label[0] == 2:\n",
    "            flatLabel[2] = 1\n",
    "        elif label[0] == 3:\n",
    "            flatLabel[3] = 1\n",
    "        elif label[0] == 4:\n",
    "            flatLabel[4] = 1\n",
    "        if label[1] == 1:\n",
    "            flatLabel[5] = 1\n",
    "        if label[2] == 1:\n",
    "            flatLabel[6] = 1\n",
    "        if label[3] == 1:\n",
    "            flatLabel[7] = 1\n",
    "        flatLabels.append(flatLabel)\n",
    "    return flatLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T09:46:27.537414Z",
     "start_time": "2020-08-28T09:46:27.527453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n",
      "[4 0 0 0]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(yVal[0])\n",
    "print(yVal_r[0])\n",
    "print(getFlatLabel(yVal_r)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:45:23.953237Z",
     "start_time": "2020-09-11T08:45:23.939275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: [[14656, 1426, 12153, 3892, 2863], [32770, 2220], [32277, 2713], [33195, 1795]]\n",
      "all good\n"
     ]
    }
   ],
   "source": [
    "num_exp = [[0,0,0,0,0],[0,0],[0,0],[0,0]]\n",
    "classes = [[[0,1,2,3,4],[5,6],[7,8,9,10],[11,12,13,14],[15,16,17]],[[0,1,2,5,6,7,8,9,11,12,13,15,16,17],[3,4,10,14]],\n",
    "           [[0,1,3,5,7,8,10,11,12,14,15,16],[2,4,6,9,13,17]],[[0,2,3,4,5,6,7,9,10,11,13,14,15,17],[1,8,12,16]]]\n",
    "for branch in range(len(num_exp)):\n",
    "    for c in range(len(num_exp[branch])):\n",
    "        sum_exp = 0\n",
    "        for s in classes[branch][c]:\n",
    "            sum_exp = sum_exp + train_it.classes[train_it.classes==s].shape[0]\n",
    "        num_exp[branch][c] = sum_exp\n",
    "print('Number of samples: '+str(num_exp))\n",
    "if np.sum(num_exp[0])== np.sum(num_exp[1]) == np.sum(num_exp[2]) == np.sum(num_exp[3]):\n",
    "    print('all good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:45:25.711245Z",
     "start_time": "2020-09-11T08:45:25.701272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20334, 14656],\n",
       " [33564, 1426],\n",
       " [22837, 12153],\n",
       " [31098, 3892],\n",
       " [32127, 2863],\n",
       " [32770, 2220],\n",
       " [32277, 2713],\n",
       " [33195, 1795]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_exp_new = [[np.sum(num_exp[0])-num_exp[0][0],num_exp[0][0]],\n",
    "              [np.sum(num_exp[0])-num_exp[0][1],num_exp[0][1]],\n",
    "              [np.sum(num_exp[0])-num_exp[0][2],num_exp[0][2]],\n",
    "              [np.sum(num_exp[0])-num_exp[0][3],num_exp[0][3]],\n",
    "              [np.sum(num_exp[0])-num_exp[0][4],num_exp[0][4]],\n",
    "              [num_exp[1][0],num_exp[1][1]],\n",
    "              [num_exp[2][0],num_exp[2][1]],\n",
    "              [num_exp[3][0],num_exp[3][1]],]\n",
    "\n",
    "num_exp_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:45:48.575306Z",
     "start_time": "2020-09-11T08:45:48.505411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: \n",
      "[0.86 1.19]\n",
      "[ 0.52 12.27]\n",
      "[0.77 1.44]\n",
      "[0.56 4.5 ]\n",
      "[0.54 6.11]\n",
      "[0.53 7.88]\n",
      "[0.54 6.45]\n",
      "[0.53 9.75]\n"
     ]
    }
   ],
   "source": [
    "flat_weights = [[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0],[0,0]]\n",
    "print('Class Weights: ')\n",
    "for branch in range(8):\n",
    "    bincount = np.array(num_exp_new[branch])\n",
    "    weights = np.sum(bincount) / (bincount.shape[0] * bincount)\n",
    "    flat_weights[branch] = weights\n",
    "    print(np.round(weights,2))\n",
    "flat_weights = np.array(flat_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:45:50.840641Z",
     "start_time": "2020-09-11T08:45:50.836652Z"
    }
   },
   "outputs": [],
   "source": [
    "NExp = np.sum(num_exp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:45:51.891073Z",
     "start_time": "2020-09-11T08:45:51.886074Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('[0, 0, 0, 0]', 0), ('[0, 0, 0, 1]', 1), ('[0, 0, 1, 0]', 2), ('[0, 1, 0, 0]', 3), ('[0, 1, 1, 0]', 4), ('[1, 0, 0, 0]', 5), ('[1, 0, 1, 0]', 6), ('[2, 0, 0, 0]', 7), ('[2, 0, 0, 1]', 8), ('[2, 0, 1, 0]', 9), ('[2, 1, 0, 0]', 10), ('[3, 0, 0, 0]', 11), ('[3, 0, 0, 1]', 12), ('[3, 0, 1, 0]', 13), ('[3, 1, 0, 0]', 14), ('[4, 0, 0, 0]', 15), ('[4, 0, 0, 1]', 16), ('[4, 0, 1, 0]', 17)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_it.class_indices.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Index Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:45:54.338812Z",
     "start_time": "2020-09-11T08:45:54.331830Z"
    }
   },
   "outputs": [],
   "source": [
    "'''@misc{guest2017gini,\n",
    "  author = \"Olivia Guest\",\n",
    "  title = \"Using the Gini Coefficient to Evaluate Deep Neural Network Layer Representations\",\n",
    "  year = \"2017\",\n",
    "  howpublished = \"Blog post\",\n",
    "  url = \"http://neuroplausible.com/gini\"\n",
    "}'''\n",
    "def gini(array):\n",
    "    \"\"\"Calculate the Gini coefficient of a numpy array.\"\"\"\n",
    "    # based on bottom eq: http://www.statsdirect.com/help/content/image/stat0206_wmf.gif\n",
    "    # from: http://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm\n",
    "    array = array.flatten() #all values are treated equally, arrays must be 1d\n",
    "    #array = np.abs(array)# change from original code\n",
    "    #if np.amin(array) < 0:\n",
    "     #   array -= np.amin(array) #values cannot be negative\n",
    "    array += 0.0000001 #values cannot be 0\n",
    "    array = np.sort(array) #values must be sorted\n",
    "    index = np.arange(1,array.shape[0]+1) #index per array element\n",
    "    n = array.shape[0]#number of array elements\n",
    "    return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array))) #Gini coefficient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:45:58.467541Z",
     "start_time": "2020-09-11T08:45:56.058257Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"./Results/TowerTraining/Recordings/Standard/3999_16.100/\"\n",
    "obs = np.load(path+\"visobs.npy\")\n",
    "hand_l = pd.read_csv(path+'HandLabels.csv')\n",
    "label_test = np.zeros(obs.shape[0])\n",
    "label_test = np.array(hand_l['Label'])\n",
    "def addLabel(currL,ToAdd):\n",
    "    if ToAdd<=1:\n",
    "        return currL\n",
    "    elif ToAdd==2:\n",
    "        currL[0] = 4\n",
    "    elif ToAdd==3:\n",
    "        currL[0] = 2\n",
    "    elif ToAdd==4:\n",
    "        currL[0] = 3\n",
    "    elif ToAdd==5:\n",
    "        currL[0] = 4\n",
    "    elif ToAdd==6:\n",
    "        currL[0]=1\n",
    "    elif ToAdd==7:\n",
    "        currL[1]=1\n",
    "    elif ToAdd==8:\n",
    "        currL[2]=1\n",
    "    elif ToAdd==9:\n",
    "        currL[3]=1\n",
    "    else:\n",
    "        print(ToAdd)\n",
    "    return currL\n",
    "\n",
    "def formatLabels(labels1,labels2):\n",
    "    formatted = []\n",
    "    for i,l in enumerate(labels1):\n",
    "        newLabel=[0,0,0,0]\n",
    "        if l == 0:\n",
    "            print(i)\n",
    "        newLabel = addLabel(newLabel,l)\n",
    "        #print(str(i)+': '+str(newLabel)+ '  '+str(l))\n",
    "        newLabel = addLabel(newLabel,labels2[i])\n",
    "        #print(str(i)+': '+str(newLabel)+ '  '+str(labels2[i]))\n",
    "        formatted.append(newLabel)\n",
    "    return np.array(formatted)\n",
    "\n",
    "fLabels = formatLabels(np.array(hand_l['Label']),np.array(hand_l['Secondary label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Classification\n",
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T10:26:42.927861Z",
     "start_time": "2020-09-11T10:26:41.731687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'dense/Softmax:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_1/Softmax:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_2/Softmax:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_3/Softmax:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_4/Softmax:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_5/Softmax:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_6/Softmax:0' shape=(?, 2) dtype=float32>, <tf.Tensor 'dense_7/Softmax:0' shape=(?, 2) dtype=float32>]\n",
      "Tensor(\"concat_1:0\", shape=(?, 8), dtype=int64)\n",
      "Tensor(\"Const_1:0\", shape=(8, 2), dtype=float32)\n",
      "Tensor(\"SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:0\", shape=(?,), dtype=float32)\n",
      "weights\n",
      "Tensor(\"Sum:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits:0\", shape=(?,), dtype=float32)\n",
      "weights\n",
      "Tensor(\"Sum_1:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits:0\", shape=(?,), dtype=float32)\n",
      "weights\n",
      "Tensor(\"Sum_2:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits:0\", shape=(?,), dtype=float32)\n",
      "weights\n",
      "Tensor(\"Sum_3:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits:0\", shape=(?,), dtype=float32)\n",
      "weights\n",
      "Tensor(\"Sum_4:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"SparseSoftmaxCrossEntropyWithLogits_5/SparseSoftmaxCrossEntropyWithLogits:0\", shape=(?,), dtype=float32)\n",
      "weights\n",
      "Tensor(\"Sum_5:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"SparseSoftmaxCrossEntropyWithLogits_6/SparseSoftmaxCrossEntropyWithLogits:0\", shape=(?,), dtype=float32)\n",
      "weights\n",
      "Tensor(\"Sum_6:0\", shape=(?,), dtype=float32)\n",
      "Tensor(\"SparseSoftmaxCrossEntropyWithLogits_7/SparseSoftmaxCrossEntropyWithLogits:0\", shape=(?,), dtype=float32)\n",
      "weights\n",
      "Tensor(\"Sum_7:0\", shape=(?,), dtype=float32)\n",
      "[<tf.Tensor 'SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:0' shape=(?,) dtype=float32>, <tf.Tensor 'SparseSoftmaxCrossEntropyWithLogits_1/SparseSoftmaxCrossEntropyWithLogits:0' shape=(?,) dtype=float32>, <tf.Tensor 'SparseSoftmaxCrossEntropyWithLogits_2/SparseSoftmaxCrossEntropyWithLogits:0' shape=(?,) dtype=float32>, <tf.Tensor 'SparseSoftmaxCrossEntropyWithLogits_3/SparseSoftmaxCrossEntropyWithLogits:0' shape=(?,) dtype=float32>, <tf.Tensor 'SparseSoftmaxCrossEntropyWithLogits_4/SparseSoftmaxCrossEntropyWithLogits:0' shape=(?,) dtype=float32>, <tf.Tensor 'SparseSoftmaxCrossEntropyWithLogits_5/SparseSoftmaxCrossEntropyWithLogits:0' shape=(?,) dtype=float32>, <tf.Tensor 'SparseSoftmaxCrossEntropyWithLogits_6/SparseSoftmaxCrossEntropyWithLogits:0' shape=(?,) dtype=float32>, <tf.Tensor 'SparseSoftmaxCrossEntropyWithLogits_7/SparseSoftmaxCrossEntropyWithLogits:0' shape=(?,) dtype=float32>]\n",
      "[<tf.Tensor 'mul_1:0' shape=(?,) dtype=float32>, <tf.Tensor 'mul_3:0' shape=(?,) dtype=float32>, <tf.Tensor 'mul_5:0' shape=(?,) dtype=float32>, <tf.Tensor 'mul_7:0' shape=(?,) dtype=float32>, <tf.Tensor 'mul_9:0' shape=(?,) dtype=float32>, <tf.Tensor 'mul_11:0' shape=(?,) dtype=float32>, <tf.Tensor 'mul_13:0' shape=(?,) dtype=float32>, <tf.Tensor 'mul_15:0' shape=(?,) dtype=float32>]\n",
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def swish(input_activation):\n",
    "    \"\"\"Swish activation function. For more info: https://arxiv.org/abs/1710.05941\"\"\"\n",
    "    return tf.multiply(input_activation, tf.nn.sigmoid(input_activation))\n",
    "\n",
    "o_size_h = 168\n",
    "o_size_w = 168\n",
    "num_layers = 2\n",
    "h_size = 256\n",
    "h_size_vec = 256\n",
    "            \n",
    "visual_in = tf.placeholder(shape=[None, o_size_h, o_size_w, 3], dtype=tf.float32,name=\"visual_observation_0\")\n",
    "labels = tf.placeholder(shape=[None,8], dtype=tf.int64,name=\"labels\")\n",
    "\n",
    "def create_vector_observation_encoder(observation_input, h_size, activation, num_layers, scope,reuse):\n",
    "    with tf.variable_scope(scope):\n",
    "        hidden_vec = observation_input\n",
    "        for i in range(num_layers):\n",
    "            hidden_vec = tf.layers.dense(hidden_vec, h_size, activation=activation, reuse=reuse,name=\"hidden_{}\".format(i),kernel_initializer=c_layers.variance_scaling_initializer(1.0))\n",
    "    return hidden_vec\n",
    "\n",
    "def create_visual_observation_encoder(image_input, h_size, activation, num_layers, scope,reuse):\n",
    "    with tf.variable_scope(scope):\n",
    "        conv1 = tf.layers.conv2d(image_input, 16, kernel_size=[8, 8], strides=[4, 4],activation=tf.nn.elu, reuse=reuse, name=\"conv_1\")\n",
    "        conv2 = tf.layers.conv2d(conv1, 32, kernel_size=[4, 4], strides=[2, 2],activation=tf.nn.elu, reuse=reuse, name=\"conv_2\")\n",
    "        hidden_vis = c_layers.flatten(conv2)\n",
    "\n",
    "    with tf.variable_scope(scope + '/' + 'flat_encoding'):\n",
    "        hidden_flat = create_vector_observation_encoder(hidden_vis, h_size, activation,num_layers, scope, reuse)\n",
    "    return hidden_flat\n",
    "\n",
    "visual_encoders = []\n",
    "\n",
    "encoded_visual = create_visual_observation_encoder(visual_in,h_size,swish,num_layers,\"main_graph_0_encoder0\", False)\n",
    "visual_encoders.append(encoded_visual)\n",
    "hidden = tf.concat(visual_encoders, axis=1)\n",
    "\n",
    "out_acts = []\n",
    "for o in range(8):\n",
    "    out_acts.append(tf.layers.dense(hidden, 2, activation=tf.nn.softmax, use_bias=False,kernel_initializer=c_layers.variance_scaling_initializer(factor=0.01)))\n",
    "print(out_acts)\n",
    "\n",
    "output = tf.concat([tf.multinomial(tf.log(out_acts[k]), 1) for k in range(8)], axis=1)#sample outputs from log probdist\n",
    "print(output)\n",
    "\n",
    "comparison = tf.equal(labels, output)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(comparison, dtype=tf.float32))\n",
    "\n",
    "class_weights = tf.constant(flat_weights,dtype='float32')\n",
    "print(class_weights)\n",
    "\n",
    "cross_entropies = []\n",
    "weighted_cross_entropies = []\n",
    "for c in range(8):\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = out_acts[c], labels = labels[:,c])\n",
    "    print(cross_entropy)\n",
    "    cross_entropies.append(cross_entropy)\n",
    "    weights = tf.reduce_sum(class_weights[c] * tf.one_hot(labels[:,c],2), axis=1)\n",
    "    print('weights')\n",
    "    print(weights)\n",
    "    scaled_error = cross_entropy * weights\n",
    "    weighted_cross_entropies.append(scaled_error)\n",
    "\n",
    "print(cross_entropies)\n",
    "print(weighted_cross_entropies)\n",
    "\n",
    "mean_cross_entropy = tf.reduce_mean(weighted_cross_entropies)\n",
    "print(mean_cross_entropy)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.0001)\n",
    "\n",
    "gradients = optimizer.compute_gradients(mean_cross_entropy)\n",
    "hidden_grad = tf.gradients(mean_cross_entropy,hidden)\n",
    "\n",
    "training_step = optimizer.minimize(mean_cross_entropy)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:59:31.672622Z",
     "start_time": "2020-09-11T08:59:31.662648Z"
    }
   },
   "outputs": [],
   "source": [
    "def getOutStats(out,fL):\n",
    "    c = plt.hist(np.array(out)+np.array(fL)/2, bins = [0,0.5,1,1.5,2])\n",
    "    precision = np.round(np.array(c[0])[:,3]/(np.array(c[0])[:,3]+np.array(c[0])[:,2])*100,2)# If L is predicted it is correct X% of time\n",
    "    recall = np.round(np.array(c[0])[:,3]/(np.array(c[0])[:,3]+np.array(c[0])[:,1])*100,2)# Correctly identifies X% of L\n",
    "    f1score = np.round(2*(precision*recall/(precision+recall)),2)\n",
    "    return precision, recall, f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T17:59:46.776285Z",
     "start_time": "2020-09-11T10:27:20.746295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Entropy    Accuracy\n",
      "epoch 0 sample output: [1 1 1 1 0 0 0 0]\n",
      "[46.41  6.49 45.95 20.61  9.93 12.41 17.11  7.25]\n",
      "Validation:  0.6765748 - 0.4970703\n",
      "Test:  0.80026966 - 0.49996874 - Gini: 0.434\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vkakerbeck\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 sample output: [1 1 1 0 0 1 1 1]\n",
      "[63.24 11.33 40.   15.27 28.31  9.16 14.2  12.31]\n",
      "Training: 0.6028093 - 0.55078125    Validation:  0.6320245 - 0.58203125\n",
      "Test:  0.73901474 - 0.5715625 - Gini: 0.525\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 2 sample output: [1 0 0 0 0 1 0 0]\n",
      "[67.02  6.97 43.4  31.33 26.86 13.85  8.33 17.39]\n",
      "Training: 0.5904514 - 0.66015625    Validation:  0.65629196 - 0.6347656\n",
      "Test:  0.6952178 - 0.62653124 - Gini: 0.501\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 3 sample output: [0 0 0 1 1 1 1 1]\n",
      "[70.43 35.3  51.14 31.58 38.53 22.82 13.53 18.19]\n",
      "Training: 0.5454902 - 0.6899414    Validation:  0.5933485 - 0.67285156\n",
      "Test:  0.64953625 - 0.64821875 - Gini: 0.491\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 4 sample output: [0 0 0 0 0 1 1 0]\n",
      "[66.66   nan 59.26 47.62 30.77 50.   14.28   nan]\n",
      "Training: 0.54745513 - 0.76123047    Validation:  0.5151245 - 0.75641024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vkakerbeck\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\vkakerbeck\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  0.6330647 - 0.7172812 - Gini: 0.499\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 5 sample output: [0 0 1 0 0 1 1 0]\n",
      "[70.05 35.89 54.16 43.25 55.7  15.88 18.18 42.86]\n",
      "Training: 0.5256431 - 0.7636719    Validation:  0.5006032 - 0.7685547\n",
      "Test:  0.6343869 - 0.72175 - Gini: 0.503\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 6 sample output: [1 0 0 0 1 0 1 0]\n",
      "[73.49 41.38 59.69 32.78 35.79 20.51 31.7  23.15]\n",
      "Training: 0.5072137 - 0.77734375    Validation:  0.50143373 - 0.7480469\n",
      "Test:  0.60996777 - 0.7156875 - Gini: 0.515\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 7 sample output: [1 0 0 0 0 1 0 0]\n",
      "[70.48 14.28 65.3  38.41 54.24 36.78 20.59 22.23]\n",
      "Training: 0.50628066 - 0.80908203    Validation:  0.5490922 - 0.79003906\n",
      "Test:  0.64832395 - 0.7555625 - Gini: 0.525\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 8 sample output: [0 0 0 1 0 0 0 0]\n",
      "[74.44 70.   65.95 34.78 53.01 34.62 35.44 23.19]\n",
      "Training: 0.49498677 - 0.8066406    Validation:  0.49364632 - 0.79833984\n",
      "Test:  0.6205332 - 0.7489375 - Gini: 0.526\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 9 sample output: [0 1 0 1 1 0 0 0]\n",
      "[78.57 48.65 70.33 26.86 50.   41.56 44.15 31.59]\n",
      "Training: 0.49859232 - 0.84375    Validation:  0.4630828 - 0.8154297\n",
      "Test:  0.6140664 - 0.75159377 - Gini: 0.532\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 10 sample output: [1 0 0 0 0 0 1 0]\n",
      "[76.86 70.   55.76 42.62 46.34 17.91 29.88 33.33]\n",
      "Training: 0.4623356 - 0.8334961    Validation:  0.4877953 - 0.80029297\n",
      "Test:  0.60658073 - 0.76346874 - Gini: 0.543\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 11 sample output: [0 0 1 1 0 1 0 0]\n",
      "[76.65 95.24 66.34 44.45 57.63 27.96 34.49 50.  ]\n",
      "Training: 0.41806847 - 0.85498047    Validation:  0.4741078 - 0.83496094\n",
      "Test:  0.6497788 - 0.77678126 - Gini: 0.544\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 12 sample output: [1 0 0 0 0 1 0 0]\n",
      "[80.7  86.96 65.14 41.74 76.6  24.99 35.44 45.  ]\n",
      "Training: 0.46438155 - 0.8535156    Validation:  0.44992468 - 0.84716797\n",
      "Test:  0.62678576 - 0.783625 - Gini: 0.548\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 13 sample output: [0 0 1 0 0 0 0 0]\n",
      "[77.07 75.86 72.32 50.   72.   31.58 33.8  36.37]\n",
      "Training: 0.42601663 - 0.86376953    Validation:  0.49046397 - 0.8457031\n",
      "Test:  0.6168032 - 0.78328127 - Gini: 0.546\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 14 sample output: [0 0 1 0 0 0 0 0]\n",
      "[83.9  68.96 71.74 50.5  57.14 29.63 33.85 32.65]\n",
      "Training: 0.4169897 - 0.875    Validation:  0.45386338 - 0.8618164\n",
      "Test:  0.6119917 - 0.7904375 - Gini: 0.554\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 15 sample output: [1 0 1 0 0 0 0 0]\n",
      "[76.47 50.   64.98 63.27 57.63 47.83 31.88 32.88]\n",
      "Training: 0.4014436 - 0.8676758    Validation:  0.4831985 - 0.8330078\n",
      "Test:  0.6103678 - 0.78746873 - Gini: 0.55\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 16 sample output: [1 0 0 0 0 0 0 0]\n",
      "[81.45 50.   70.05 59.34 51.85 48.39 28.17 47.06]\n",
      "Training: 0.4374335 - 0.8666992    Validation:  0.46185035 - 0.86572266\n",
      "Test:  0.6238699 - 0.80575 - Gini: 0.557\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 17 sample output: [0 0 1 1 0 0 0 0]\n",
      "[79.83 69.57 69.37 55.81 65.52 31.58 56.71 41.67]\n",
      "Training: 0.42631048 - 0.89501953    Validation:  0.47464105 - 0.8720703\n",
      "Test:  0.6190989 - 0.8160625 - Gini: 0.558\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 18 sample output: [0 0 0 1 0 0 0 0]\n",
      "[74.87 61.54 75.   48.6  78.57 37.93 22.22 54.55]\n",
      "Training: 0.38542652 - 0.8847656    Validation:  0.50833654 - 0.86376953\n",
      "Test:  0.6110189 - 0.8123125 - Gini: 0.557\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 19 sample output: [0 0 1 0 0 0 0 0]\n",
      "[79.62 66.67 69.19 60.24 62.3  51.29 35.82 37.74]\n",
      "Training: 0.37870467 - 0.90771484    Validation:  0.47131324 - 0.8730469\n",
      "Test:  0.60309106 - 0.81790626 - Gini: 0.556\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 20 sample output: [1 0 0 0 0 1 0 1]\n",
      "[ 85.72 100.    69.57  80.    66.67  50.    36.36  75.  ]\n",
      "Training: 0.40001667 - 0.92041016    Validation:  0.41654548 - 0.8974359\n",
      "Test:  0.6159597 - 0.8215625 - Gini: 0.56\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 21 sample output: [0 0 1 1 0 0 0 0]\n",
      "[83.49 75.86 75.82 51.06 57.14 41.67 45.16 55.32]\n",
      "Training: 0.3934989 - 0.90722656    Validation:  0.44103888 - 0.8857422\n",
      "Test:  0.6084718 - 0.8194063 - Gini: 0.562\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 22 sample output: [0 0 1 0 0 0 0 0]\n",
      "[82.35 81.82 67.45 61.18 70.   43.24 50.   47.06]\n",
      "Training: 0.3866462 - 0.9189453    Validation:  0.42041472 - 0.89453125\n",
      "Test:  0.6138345 - 0.8290625 - Gini: 0.561\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 23 sample output: [0 0 1 0 0 0 0 0]\n",
      "[84.55 54.55 75.73 51.72 72.41 45.   46.51 66.67]\n",
      "Training: 0.38560858 - 0.9213867    Validation:  0.41228923 - 0.9082031\n",
      "Test:  0.6229045 - 0.8368437 - Gini: 0.558\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 24 sample output: [0 0 0 1 0 1 0 0]\n",
      "[82.97 84.21 72.63 64.2  84.21 38.3  47.62 75.  ]\n",
      "Training: 0.373765 - 0.93896484    Validation:  0.4623987 - 0.90966797\n",
      "Test:  0.65502894 - 0.83921874 - Gini: 0.557\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 25 sample output: [1 0 0 0 0 0 0 0]\n",
      "[85.85 60.   77.08 61.33 73.34 43.9  50.   65.22]\n",
      "Training: 0.38065293 - 0.9394531    Validation:  0.46866757 - 0.9033203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  0.6255027 - 0.8422812 - Gini: 0.561\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 26 sample output: [1 0 0 0 0 0 0 0]\n",
      "[82.73 66.67 69.61 65.67 72.22 48.65 48.98 37.21]\n",
      "Training: 0.3633265 - 0.94384766    Validation:  0.45516568 - 0.9003906\n",
      "Test:  0.6052557 - 0.84534377 - Gini: 0.56\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 27 sample output: [0 0 1 0 0 0 0 0]\n",
      "[83.84 60.87 79.41 53.85 73.34 50.   54.54 68.75]\n",
      "Training: 0.3616319 - 0.9555664    Validation:  0.4711039 - 0.9135742\n",
      "Test:  0.6438743 - 0.843 - Gini: 0.562\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 28 sample output: [0 0 1 1 0 0 0 0]\n",
      "[76.77 72.72 73.85 65.63 69.24 46.16 36.73 61.11]\n",
      "Training: 0.36161274 - 0.94433594    Validation:  0.5097476 - 0.9003906\n",
      "Test:  0.6440545 - 0.85146874 - Gini: 0.562\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 29 sample output: [0 0 1 0 0 0 0 0]\n",
      "[85.15 88.   78.61 75.36 79.31 52.17 54.24 72.73]\n",
      "Training: 0.38236225 - 0.95751953    Validation:  0.47449663 - 0.92333984\n",
      "Test:  0.6411924 - 0.85159373 - Gini: 0.563\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 30 sample output: [0 0 0 1 0 0 0 0]\n",
      "[87.55 66.67 73.05 77.92 82.05 33.33 54.55 83.33]\n",
      "Training: 0.37037712 - 0.94091797    Validation:  0.44221306 - 0.9272461\n",
      "Test:  0.65878296 - 0.854625 - Gini: 0.566\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 31 sample output: [0 0 1 0 0 0 0 0]\n",
      "[80.75 72.72 78.95 66.67 75.86 21.05 47.27 84.21]\n",
      "Training: 0.36906326 - 0.95214844    Validation:  0.42887157 - 0.91796875\n",
      "Test:  0.6554236 - 0.85253125 - Gini: 0.564\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 32 sample output: [0 0 0 0 1 0 0 0]\n",
      "[87.78 88.   71.62 72.98 70.37 63.41 51.28 74.28]\n",
      "Training: 0.3615232 - 0.9663086    Validation:  0.45591676 - 0.92626953\n",
      "Test:  0.65482646 - 0.8554062 - Gini: 0.561\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 33 sample output: [1 0 0 0 0 0 0 0]\n",
      "[90.91 72.72 77.01 53.12 75.86 52.17 48.   80.  ]\n",
      "Training: 0.35736045 - 0.9716797    Validation:  0.44912246 - 0.92333984\n",
      "Test:  0.6588444 - 0.8546875 - Gini: 0.563\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 34 sample output: [1 0 0 0 0 0 0 0]\n",
      "[82.12 53.33 74.29 58.97 86.2  59.46 65.38 66.67]\n",
      "Training: 0.34311277 - 0.9667969    Validation:  0.47266942 - 0.91503906\n",
      "Test:  0.64509255 - 0.86075 - Gini: 0.558\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 35 sample output: [0 0 1 0 0 0 1 0]\n",
      "[88.   94.12 85.71 72.73 88.37 61.22 64.   80.  ]\n",
      "Training: 0.34788042 - 0.97265625    Validation:  0.39823475 - 0.94189453\n",
      "Test:  0.6533108 - 0.86146873 - Gini: 0.559\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 36 sample output: [0 0 0 0 0 1 0 0]\n",
      "[80.     nan 81.25 76.92 85.71 66.67 57.14   nan]\n",
      "Training: 0.34288207 - 0.9707031    Validation:  0.58559775 - 0.92628205\n",
      "Test:  0.65413916 - 0.8604063 - Gini: 0.557\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 37 sample output: [1 0 0 0 0 0 1 0]\n",
      "[86.83 88.89 78.54 82.35 75.68 61.54 71.7  75.  ]\n",
      "Training: 0.38322037 - 0.97021484    Validation:  0.42960244 - 0.9404297\n",
      "Test:  0.65758276 - 0.8634375 - Gini: 0.558\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 38 sample output: [0 0 0 0 0 0 0 0]\n",
      "[84.48 77.78 67.97 63.34 83.72 34.78 61.11 70.59]\n",
      "Training: 0.36685735 - 0.9741211    Validation:  0.48835984 - 0.92333984\n",
      "Test:  0.6634574 - 0.866625 - Gini: 0.558\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 39 sample output: [1 0 0 0 0 0 0 0]\n",
      "[85.33 66.67 81.21 72.73 79.07 57.14 55.55 80.  ]\n",
      "Training: 0.328894 - 0.9760742    Validation:  0.46737325 - 0.9316406\n",
      "Test:  0.6536492 - 0.8644375 - Gini: 0.561\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 40 sample output: [0 0 0 0 0 0 0 0]\n",
      "[90.53 72.72 82.87 50.   80.95 62.5  62.22 78.26]\n",
      "Training: 0.33904076 - 0.9741211    Validation:  0.43758917 - 0.94091797\n",
      "Test:  0.6619955 - 0.86771876 - Gini: 0.558\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 41 sample output: [1 0 0 0 0 0 0 0]\n",
      "[ 81.95  71.43  73.45  80.65  87.72  68.97  60.6  100.  ]\n",
      "Training: 0.34887418 - 0.97802734    Validation:  0.42915368 - 0.9370117\n",
      "Test:  0.6663127 - 0.8679063 - Gini: 0.555\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 42 sample output: [0 0 0 0 0 0 0 0]\n",
      "[86.96 75.   77.71 74.63 79.07 46.67 43.9  72.73]\n",
      "Training: 0.36092767 - 0.9770508    Validation:  0.4727114 - 0.93115234\n",
      "Test:  0.6724114 - 0.86775 - Gini: 0.559\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 43 sample output: [0 0 1 0 0 0 0 0]\n",
      "[77.   62.5  77.07 53.06 83.72 64.29 50.   80.  ]\n",
      "Training: 0.33796608 - 0.9848633    Validation:  0.48290682 - 0.9194336\n",
      "Test:  0.6726794 - 0.867875 - Gini: 0.557\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 44 sample output: [0 0 1 0 0 0 1 0]\n",
      "[86.63 66.66 78.21 78.69 93.62 48.   64.   64.52]\n",
      "Training: 0.3408375 - 0.9790039    Validation:  0.44681904 - 0.94091797\n",
      "Test:  0.6716186 - 0.86771876 - Gini: 0.558\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 45 sample output: [0 0 0 1 0 0 0 0]\n",
      "[84.78 86.95 81.67 77.14 91.3  70.   53.33 69.57]\n",
      "Training: 0.3528117 - 0.9791667    Validation:  0.46446198 - 0.93847656\n",
      "Test:  0.67658436 - 0.86521876 - Gini: 0.556\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 46 sample output: [0 0 0 0 0 0 0 0]\n",
      "[86.36 84.21 80.72 79.36 91.67 66.67 65.31 74.07]\n",
      "Training: 0.3326245 - 0.9785156    Validation:  0.45794654 - 0.94384766\n",
      "Test:  0.6668625 - 0.87140626 - Gini: 0.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 47 sample output: [1 0 0 0 0 0 0 0]\n",
      "[80.89 86.96 71.17 70.   81.08 70.27 69.57 91.89]\n",
      "Training: 0.3464285 - 0.9794922    Validation:  0.44995677 - 0.92871094\n",
      "Test:  0.665886 - 0.8693125 - Gini: 0.559\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 48 sample output: [0 0 1 1 0 0 0 0]\n",
      "[83.41 66.67 75.   70.   80.   43.48 53.85 76.93]\n",
      "Training: 0.34324098 - 0.9873047    Validation:  0.48815557 - 0.92333984\n",
      "Test:  0.6627661 - 0.87075 - Gini: 0.554\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 49 sample output: [1 0 0 0 0 0 0 0]\n",
      "[84.75 77.78 74.53 73.53 81.25 45.45 67.86 82.76]\n",
      "Training: 0.36025518 - 0.9765625    Validation:  0.46570498 - 0.9316406\n",
      "Test:  0.6665547 - 0.8733125 - Gini: 0.557\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 50 sample output: [0 0 0 0 1 0 0 0]\n",
      "[88.11 80.   81.08 71.19 73.33 51.43 45.16 88.  ]\n",
      "Training: 0.32877177 - 0.98583984    Validation:  0.44770107 - 0.9379883\n",
      "Test:  0.6668845 - 0.8690938 - Gini: 0.555\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 51 sample output: [0 0 1 0 0 0 0 0]\n",
      "[82.41 76.19 73.86 70.83 84.61 40.   46.51 66.67]\n",
      "Training: 0.33539847 - 0.9838867    Validation:  0.48958242 - 0.92529297\n",
      "Test:  0.6704132 - 0.87325 - Gini: 0.557\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 52 sample output: [1 0 0 0 0 0 1 0]\n",
      "[90.48 66.67 80.   66.67 66.67 85.71 72.72 80.  ]\n",
      "Training: 0.3186528 - 0.98583984    Validation:  0.50309706 - 0.9391026\n",
      "Test:  0.65429664 - 0.8699375 - Gini: 0.563\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 53 sample output: [0 0 0 0 0 1 0 0]\n",
      "[85.11 83.33 73.94 64.51 86.49 40.   72.73 83.87]\n",
      "Training: 0.3291952 - 0.98779297    Validation:  0.44458053 - 0.9321289\n",
      "Test:  0.666536 - 0.8698125 - Gini: 0.559\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 54 sample output: [0 0 0 1 0 0 0 0]\n",
      "[87.69 71.43 82.1  86.49 78.95 65.   53.33 84.85]\n",
      "Training: 0.3209197 - 0.9848633    Validation:  0.44100568 - 0.94091797\n",
      "Test:  0.6371564 - 0.869125 - Gini: 0.564\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 55 sample output: [0 0 1 0 0 0 0 1]\n",
      "[83.84 84.61 81.56 76.   88.24 66.67 50.   75.68]\n",
      "Training: 0.32129964 - 0.9897461    Validation:  0.44349203 - 0.9399414\n",
      "Test:  0.66157544 - 0.872375 - Gini: 0.561\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 56 sample output: [1 0 0 0 0 0 0 0]\n",
      "[83.18 58.83 80.   71.88 80.   62.5  68.29 70.  ]\n",
      "Training: 0.3287461 - 0.9868164    Validation:  0.45622373 - 0.93652344\n",
      "Test:  0.667225 - 0.8720313 - Gini: 0.569\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 57 sample output: [0 0 0 0 1 0 0 0]\n",
      "[84.32 80.   79.52 67.74 90.56 82.05 47.37 66.67]\n",
      "Training: 0.34205955 - 0.97998047    Validation:  0.448354 - 0.9370117\n",
      "Test:  0.6641804 - 0.8701562 - Gini: 0.563\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 58 sample output: [1 0 0 0 0 0 0 0]\n",
      "[84.11 50.   75.29 73.85 76.19 51.62 53.66 52.94]\n",
      "Training: 0.33995813 - 0.9819336    Validation:  0.5023576 - 0.9223633\n",
      "Test:  0.6461466 - 0.87475 - Gini: 0.575\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 59 sample output: [0 0 1 0 0 0 0 0]\n",
      "[86.42 76.19 79.1  73.69 83.64 43.48 60.   81.25]\n",
      "Training: 0.34181112 - 0.9863281    Validation:  0.47958148 - 0.93896484\n",
      "Test:  0.6554779 - 0.87534374 - Gini: 0.572\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 60 sample output: [0 0 0 0 0 0 1 0]\n",
      "[83.9  47.06 77.01 77.19 88.89 51.62 61.22 90.91]\n",
      "Training: 0.34013057 - 0.9848633    Validation:  0.5106573 - 0.9326172\n",
      "Test:  0.6366103 - 0.8735312 - Gini: 0.571\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 61 sample output: [1 0 0 0 0 0 0 0]\n",
      "[85.11 81.82 80.66 76.19 83.87 38.46 66.67 85.71]\n",
      "Training: 0.31959683 - 0.99072266    Validation:  0.44207925 - 0.9399414\n",
      "Test:  0.6562216 - 0.87609375 - Gini: 0.567\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 62 sample output: [0 0 0 0 0 0 0 0]\n",
      "[79.34 93.33 73.52 65.22 83.34 62.5  52.38 83.33]\n",
      "Training: 0.32385975 - 0.98876953    Validation:  0.47453827 - 0.92285156\n",
      "Test:  0.67114484 - 0.87521875 - Gini: 0.564\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 63 sample output: [0 0 1 0 0 0 0 0]\n",
      "[86.83 94.12 80.   77.78 92.31 56.   61.11 70.59]\n",
      "Training: 0.33179665 - 0.9868164    Validation:  0.4138021 - 0.9448242\n",
      "Test:  0.6741991 - 0.8744375 - Gini: 0.562\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 64 sample output: [0 0 0 0 1 0 0 0]\n",
      "[86.24 92.31 77.   70.77 83.87 61.54 75.   88.89]\n",
      "Training: 0.34028083 - 0.98828125    Validation:  0.44000885 - 0.9399414\n",
      "Test:  0.6700261 - 0.87546873 - Gini: 0.561\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 65 sample output: [0 0 1 0 0 0 0 0]\n",
      "[87.83 78.26 85.03 77.96 84.85 50.   60.   68.97]\n",
      "Training: 0.3235191 - 0.9868164    Validation:  0.4666134 - 0.94433594\n",
      "Test:  0.6715413 - 0.87659377 - Gini: 0.559\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 66 sample output: [0 0 0 0 1 0 0 0]\n",
      "[84.69 44.44 80.7  76.92 90.57 48.28 59.65 87.5 ]\n",
      "Training: 0.32637188 - 0.99072266    Validation:  0.47839674 - 0.93603516\n",
      "Test:  0.66658324 - 0.8769063 - Gini: 0.559\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 67 sample output: [1 0 0 0 0 0 0 0]\n",
      "[81.15 76.19 71.64 67.65 85.   41.67 40.   86.49]\n",
      "Training: 0.32068512 - 0.99365234    Validation:  0.5152775 - 0.92626953\n",
      "Test:  0.6679591 - 0.8798125 - Gini: 0.558\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68 sample output: [0 0 0 0 1 0 0 0]\n",
      "[ 90.91 100.    80.    75.    87.5     nan    nan 100.  ]\n",
      "Training: 0.33431193 - 0.9892578    Validation:  0.45182633 - 0.94871795\n",
      "Test:  0.663584 - 0.87834376 - Gini: 0.559\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 69 sample output: [0 0 1 0 0 0 0 0]\n",
      "[84.85 85.71 85.4  77.61 88.89 55.56 56.41 66.67]\n",
      "Training: 0.3256663 - 0.9892578    Validation:  0.4662827 - 0.94433594\n",
      "Test:  0.66996837 - 0.8755 - Gini: 0.557\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 70 sample output: [1 0 0 0 0 0 0 0]\n",
      "[87.03 80.   77.22 69.84 86.96 63.63 62.86 92.31]\n",
      "Training: 0.33308563 - 0.9873047    Validation:  0.43755114 - 0.9433594\n",
      "Test:  0.661474 - 0.8765625 - Gini: 0.559\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 71 sample output: [0 0 1 0 1 0 0 0]\n",
      "[87.16 69.56 81.18 82.35 77.55 66.66 60.61 80.  ]\n",
      "Training: 0.36556455 - 0.98046875    Validation:  0.4677546 - 0.9428711\n",
      "Test:  0.6688673 - 0.86903125 - Gini: 0.571\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 72 sample output: [1 0 0 0 0 0 0 0]\n",
      "[82.76 66.66 77.64 64.71 91.23 44.44 60.6  80.  ]\n",
      "Training: 0.34265083 - 0.9814453    Validation:  0.46380424 - 0.9301758\n",
      "Test:  0.6804118 - 0.8683438 - Gini: 0.583\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 73 sample output: [0 0 0 1 0 0 0 0]\n",
      "[85.44 57.14 83.7  72.73 84.62 52.94 77.27 74.29]\n",
      "Training: 0.34915406 - 0.9819336    Validation:  0.44656098 - 0.9394531\n",
      "Test:  0.65888095 - 0.86428124 - Gini: 0.583\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 74 sample output: [1 0 0 0 0 0 0 0]\n",
      "[87.72 50.   84.95 70.37 80.85 64.52 63.41 79.17]\n",
      "Training: 0.356884 - 0.98779297    Validation:  0.45779854 - 0.94189453\n",
      "Test:  0.67481065 - 0.8691875 - Gini: 0.583\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 75 sample output: [0 0 1 0 0 0 0 0]\n",
      "[88.29 82.35 80.23 68.   92.68 53.84 77.27 87.5 ]\n",
      "Training: 0.3408396 - 0.9941406    Validation:  0.45638716 - 0.9472656\n",
      "Test:  0.6643695 - 0.87446874 - Gini: 0.579\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 76 sample output: [1 0 0 0 0 0 1 0]\n",
      "[86.07 60.   73.37 70.18 82.05 65.   57.15 90.  ]\n",
      "Training: 0.34053066 - 0.9892578    Validation:  0.46998703 - 0.9296875\n",
      "Test:  0.66929054 - 0.87209374 - Gini: 0.579\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 77 sample output: [1 0 0 0 0 0 0 0]\n",
      "[87.6  70.   77.55 57.14 89.36 69.23 60.   86.67]\n",
      "Training: 0.35488778 - 0.9892578    Validation:  0.4842473 - 0.9379883\n",
      "Test:  0.6751571 - 0.8743125 - Gini: 0.574\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 78 sample output: [1 0 0 0 0 0 0 0]\n",
      "[82.88 44.44 72.93 61.02 81.82 61.11 55.   80.  ]\n",
      "Training: 0.35922652 - 0.98876953    Validation:  0.51453304 - 0.92089844\n",
      "Test:  0.6743158 - 0.87375 - Gini: 0.571\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 79 sample output: [0 0 1 0 0 0 0 0]\n",
      "[88.89 91.67 77.02 79.17 63.16 55.18 72.73 80.  ]\n",
      "Training: 0.33507478 - 0.99609375    Validation:  0.48566347 - 0.9423828\n",
      "Test:  0.6683004 - 0.87834376 - Gini: 0.572\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 80 sample output: [0 0 0 0 0 0 0 1]\n",
      "[ 85.45  95.24  76.41  84.21 100.    46.15  42.43  73.69]\n",
      "Training: 0.33692795 - 0.99121094    Validation:  0.43195856 - 0.94091797\n",
      "Test:  0.66772294 - 0.8777813 - Gini: 0.571\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 81 sample output: [0 0 1 0 0 0 0 0]\n",
      "[84.1  77.78 77.18 76.47 72.73 61.54 34.78 75.  ]\n",
      "Training: 0.3266102 - 0.99365234    Validation:  0.46329066 - 0.93359375\n",
      "Test:  0.67526156 - 0.8756875 - Gini: 0.569\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 82 sample output: [0 0 1 0 0 0 0 0]\n",
      "[81.03 80.   81.37 71.43 77.42 55.56 57.15 63.16]\n",
      "Training: 0.32453448 - 0.9951172    Validation:  0.44127434 - 0.93408203\n",
      "Test:  0.6683706 - 0.879875 - Gini: 0.57\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 83 sample output: [1 0 0 0 0 0 0 0]\n",
      "[84.71 76.19 78.36 77.42 78.26 42.86 66.66 93.33]\n",
      "Training: 0.3258171 - 0.9902344    Validation:  0.47803876 - 0.93847656\n",
      "Test:  0.6668306 - 0.8778125 - Gini: 0.569\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 84 sample output: [0 0 1 0 0 0 0 0]\n",
      "[ 85.   100.    69.23 100.    50.      nan  80.    50.  ]\n",
      "Training: 0.3286537 - 0.99658203    Validation:  0.47913757 - 0.92948717\n",
      "Test:  0.67098683 - 0.8771875 - Gini: 0.568\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 85 sample output: [0 0 0 0 1 0 0 0]\n",
      "[82.41 37.5  79.38 72.   77.55 66.66 52.17 85.71]\n",
      "Training: 0.3234992 - 0.9916992    Validation:  0.5409554 - 0.9296875\n",
      "Test:  0.67633563 - 0.87653124 - Gini: 0.565\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 86 sample output: [0 0 0 1 0 0 0 0]\n",
      "[85.71 90.91 81.61 71.7  88.89 50.   72.22 69.57]\n",
      "Training: 0.3311044 - 0.99365234    Validation:  0.44234252 - 0.9433594\n",
      "Test:  0.66692746 - 0.87771875 - Gini: 0.567\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 87 sample output: [1 0 0 0 0 0 0 0]\n",
      "[85.85 36.36 76.83 77.92 80.95 50.   57.14 72.22]\n",
      "Training: 0.33085606 - 0.9946289    Validation:  0.5185505 - 0.9301758\n",
      "Test:  0.6712692 - 0.87565625 - Gini: 0.568\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 88 sample output: [0 0 1 0 0 0 0 0]\n",
      "[89.75 76.93 76.44 69.57 88.89 66.67 44.44 75.  ]\n",
      "Training: 0.32364392 - 0.99365234    Validation:  0.46231484 - 0.94433594\n",
      "Test:  0.66522306 - 0.8783125 - Gini: 0.57\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 89 sample output: [0 0 1 0 0 0 0 0]\n",
      "[85.72 88.89 73.29 72.97 90.91 52.17 46.15 82.76]\n",
      "Training: 0.32493123 - 0.9916992    Validation:  0.4309054 - 0.93603516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  0.66955435 - 0.875625 - Gini: 0.574\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 90 sample output: [1 0 0 0 0 0 0 0]\n",
      "[85.19 58.83 81.56 69.57 82.92 42.85 73.17 58.82]\n",
      "Training: 0.318475 - 0.9897461    Validation:  0.4702665 - 0.9345703\n",
      "Test:  0.6607661 - 0.87296873 - Gini: 0.586\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 91 sample output: [0 0 1 0 0 0 1 0]\n",
      "[82.24 89.66 78.61 64.71 71.43 62.07 66.67 92.86]\n",
      "Training: 0.33746406 - 0.98828125    Validation:  0.437048 - 0.9321289\n",
      "Test:  0.6644674 - 0.8661562 - Gini: 0.593\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 92 sample output: [0 0 1 0 0 0 0 0]\n",
      "[84.75 85.71 79.25 84.   73.91 47.37 80.   81.48]\n",
      "Training: 0.34134555 - 0.9824219    Validation:  0.4733964 - 0.9394531\n",
      "Test:  0.6759884 - 0.8701875 - Gini: 0.588\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 93 sample output: [0 0 1 0 0 0 0 1]\n",
      "[90.32 90.   83.25 78.26 80.85 64.51 56.52 84.85]\n",
      "Training: 0.34517807 - 0.9863281    Validation:  0.4321056 - 0.94677734\n",
      "Test:  0.66277355 - 0.8691875 - Gini: 0.588\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 94 sample output: [0 0 1 0 0 0 0 0]\n",
      "[86.01 76.92 85.03 73.47 85.19 44.44 58.83 86.67]\n",
      "Training: 0.34845608 - 0.99072266    Validation:  0.43873173 - 0.94384766\n",
      "Test:  0.6651025 - 0.87446874 - Gini: 0.588\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 95 sample output: [1 0 0 0 0 0 0 0]\n",
      "[86.6  88.89 75.   56.14 95.45 66.67 52.38 86.96]\n",
      "Training: 0.3567984 - 0.9838867    Validation:  0.46767265 - 0.9350586\n",
      "Test:  0.6606385 - 0.88065624 - Gini: 0.585\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 96 sample output: [0 0 1 0 0 0 0 0]\n",
      "[88.79 72.72 77.66 75.86 81.25 52.18 67.93 75.  ]\n",
      "Training: 0.3575428 - 0.9916992    Validation:  0.45508063 - 0.93847656\n",
      "Test:  0.6595435 - 0.8783125 - Gini: 0.584\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 97 sample output: [0 0 0 1 0 0 0 0]\n",
      "[85.45 55.56 77.2  76.67 80.95 60.   50.   81.48]\n",
      "Training: 0.31145036 - 0.99365234    Validation:  0.47656134 - 0.9345703\n",
      "Test:  0.6584719 - 0.8808125 - Gini: 0.584\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 98 sample output: [0 0 1 0 0 0 0 0]\n",
      "[84.82 66.67 76.02 76.92 91.67 71.43 61.9  88.89]\n",
      "Training: 0.3304187 - 0.9926758    Validation:  0.43981478 - 0.9404297\n",
      "Test:  0.6676669 - 0.8765 - Gini: 0.578\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 99 sample output: [0 0 1 0 0 0 0 0]\n",
      "[84.58 77.78 79.1  71.7  75.67 55.56 68.57 85.  ]\n",
      "Training: 0.3248674 - 0.99316406    Validation:  0.469988 - 0.93896484\n",
      "Test:  0.66495836 - 0.8780625 - Gini: 0.579\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 100 sample output: [0 0 1 0 0 0 0 0]\n",
      "[ 73.69    nan  84.21  83.33 100.      nan  50.   100.  ]\n",
      "Training: 0.3443855 - 0.9897461    Validation:  0.61362946 - 0.92628205\n",
      "Test:  0.658897 - 0.879375 - Gini: 0.58\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 101 sample output: [1 0 0 0 0 0 0 0]\n",
      "[84.49 81.82 68.11 66.67 77.27 58.07 60.   75.  ]\n",
      "Training: 0.3289878 - 0.99609375    Validation:  0.48286703 - 0.92871094\n",
      "Test:  0.6617872 - 0.88084376 - Gini: 0.576\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 102 sample output: [0 0 1 0 0 0 0 0]\n",
      "[85.   70.59 79.12 78.69 94.12 60.87 60.   75.  ]\n",
      "Training: 0.34477764 - 0.9921875    Validation:  0.46663934 - 0.9433594\n",
      "Test:  0.66625965 - 0.88065624 - Gini: 0.577\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 103 sample output: [0 0 0 0 1 0 0 0]\n",
      "[85.85 80.   81.14 63.34 84.21 58.07 74.42 80.  ]\n",
      "Training: 0.31487322 - 0.9921875    Validation:  0.50398576 - 0.93847656\n",
      "Test:  0.6627738 - 0.8813437 - Gini: 0.576\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 104 sample output: [1 0 0 0 0 0 0 0]\n",
      "[86.15 77.78 81.82 76.36 85.   62.5  56.52 88.  ]\n",
      "Training: 0.32165134 - 0.9941406    Validation:  0.46689022 - 0.94091797\n",
      "Test:  0.65929466 - 0.880875 - Gini: 0.577\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 105 sample output: [0 0 1 0 0 0 0 0]\n",
      "[81.91 75.   78.79 81.58 80.   30.   59.46 83.87]\n",
      "Training: 0.32786435 - 0.99121094    Validation:  0.4824815 - 0.9345703\n",
      "Test:  0.66262305 - 0.8794375 - Gini: 0.575\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 106 sample output: [0 0 1 0 0 0 0 0]\n",
      "[85.71 90.91 87.44 79.37 84.21 54.54 52.18 70.97]\n",
      "Training: 0.3283137 - 0.9916992    Validation:  0.43917733 - 0.94970703\n",
      "Test:  0.67191243 - 0.877375 - Gini: 0.574\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 107 sample output: [0 0 1 0 0 0 0 0]\n",
      "[86.11 81.82 75.   74.57 90.48 40.   68.29 84.21]\n",
      "Training: 0.3185017 - 0.9951172    Validation:  0.50104845 - 0.9370117\n",
      "Test:  0.6683312 - 0.8784375 - Gini: 0.576\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 108 sample output: [0 0 1 0 0 0 0 0]\n",
      "[86.91 66.67 86.54 61.54 87.1  13.33 54.17 72.72]\n",
      "Training: 0.33225626 - 0.99121094    Validation:  0.46273044 - 0.9375\n",
      "Test:  0.64868385 - 0.87478125 - Gini: 0.588\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 109 sample output: [1 0 0 0 0 0 0 0]\n",
      "[82.5  80.   75.18 71.43 71.11 62.07 67.93 76.19]\n",
      "Training: 0.34117892 - 0.99121094    Validation:  0.50354654 - 0.9291992\n",
      "Test:  0.6733219 - 0.878125 - Gini: 0.585\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 110 sample output: [1 0 0 0 0 0 0 0]\n",
      "[89.63 66.67 81.93 75.76 78.95 70.59 52.63 75.86]\n",
      "Training: 0.3569417 - 0.98046875    Validation:  0.40832466 - 0.9423828\n",
      "Test:  0.63175094 - 0.8649688 - Gini: 0.603\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 111 sample output: [1 0 0 0 0 0 0 0]\n",
      "[78.9  72.73 81.51 75.   84.85 63.63 59.57 78.26]\n",
      "Training: 0.31194252 - 0.9897461    Validation:  0.41789794 - 0.93310547\n",
      "Test:  0.6627416 - 0.8726562 - Gini: 0.607\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 112 sample output: [1 0 0 0 0 0 1 0]\n",
      "[85.71 66.67 78.11 74.19 76.19 58.07 55.81 71.79]\n",
      "Training: 0.36267722 - 0.9848633    Validation:  0.49753737 - 0.9301758\n",
      "Test:  0.6467595 - 0.87478125 - Gini: 0.608\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 113 sample output: [1 0 0 0 0 0 0 0]\n",
      "[82.45 76.92 77.49 65.3  80.   52.94 44.45 57.14]\n",
      "Training: 0.33272827 - 0.99365234    Validation:  0.48355693 - 0.92626953\n",
      "Test:  0.65748614 - 0.8799375 - Gini: 0.604\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 114 sample output: [1 0 0 0 0 1 0 0]\n",
      "[84.39 66.67 73.37 72.73 76.47 44.44 51.61 85.71]\n",
      "Training: 0.34003258 - 0.9926758    Validation:  0.4777418 - 0.9321289\n",
      "Test:  0.66308844 - 0.8798438 - Gini: 0.6\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 115 sample output: [1 0 0 0 0 0 0 0]\n",
      "[86.05 80.   76.73 64.52 90.91 59.26 57.14 86.96]\n",
      "Training: 0.32534963 - 0.9921875    Validation:  0.45826384 - 0.9375\n",
      "Test:  0.66976225 - 0.878125 - Gini: 0.595\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 116 sample output: [0 1 0 0 0 0 0 0]\n",
      "[ 84.62 100.    89.66  88.89  75.      nan  85.71 100.  ]\n",
      "Training: 0.34776342 - 0.9946289    Validation:  0.39537087 - 0.96153843\n",
      "Test:  0.664666 - 0.87921876 - Gini: 0.594\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "saved model\n",
      "epoch 117 sample output: [1 0 0 0 0 0 0 1]\n",
      "[86.26 88.89 83.33 78.57 85.11 59.26 59.46 81.48]\n",
      "Training: 0.35564587 - 0.99316406    Validation:  0.4507115 - 0.9458008\n",
      "Test:  0.66137326 - 0.88071877 - Gini: 0.592\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 118 sample output: [1 0 0 0 0 0 0 0]\n",
      "[84.07 85.71 80.87 83.72 82.05 58.82 70.   81.48]\n",
      "Training: 0.33946824 - 0.99365234    Validation:  0.42133015 - 0.9458008\n",
      "Test:  0.6610541 - 0.879625 - Gini: 0.59\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 119 sample output: [0 0 0 1 0 0 0 0]\n",
      "[85.04 70.59 73.29 68.57 78.05 42.86 56.52 90.91]\n",
      "Training: 0.3178333 - 0.99316406    Validation:  0.50964046 - 0.9291992\n",
      "Test:  0.66547817 - 0.879875 - Gini: 0.59\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 120 sample output: [1 0 0 0 0 0 0 0]\n",
      "[83.04 63.16 75.3  65.63 85.72 58.82 62.85 86.96]\n",
      "Training: 0.34456947 - 0.99609375    Validation:  0.47045392 - 0.9296875\n",
      "Test:  0.65957385 - 0.8798438 - Gini: 0.591\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 121 sample output: [1 0 0 0 0 0 0 0]\n",
      "[84.9  77.42 79.53 72.73 91.89 60.   61.11 88.89]\n",
      "Training: 0.32481807 - 0.99560547    Validation:  0.47281462 - 0.94140625\n",
      "Test:  0.66064173 - 0.882125 - Gini: 0.591\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 122 sample output: [0 0 0 0 0 0 0 0]\n",
      "[87.04 82.35 79.54 75.41 82.35 42.1  48.49 88.37]\n",
      "Training: 0.31615835 - 0.9916992    Validation:  0.48024198 - 0.94091797\n",
      "Test:  0.66228 - 0.8814688 - Gini: 0.588\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 123 sample output: [1 0 0 0 0 0 0 0]\n",
      "[84.68 66.67 82.98 81.82 92.68 62.07 63.64 78.79]\n",
      "Training: 0.33937943 - 0.99316406    Validation:  0.47822252 - 0.9428711\n",
      "Test:  0.6611741 - 0.8808125 - Gini: 0.588\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 124 sample output: [0 0 0 1 0 1 0 0]\n",
      "[88.69 72.72 78.05 80.   80.   72.   80.95 90.32]\n",
      "Training: 0.3323063 - 0.99121094    Validation:  0.43365204 - 0.94921875\n",
      "Test:  0.6627679 - 0.8788437 - Gini: 0.588\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 125 sample output: [1 0 0 0 0 0 0 0]\n",
      "[88.37 78.26 81.87 75.41 71.79 47.62 48.15 96.3 ]\n",
      "Training: 0.3370945 - 0.99072266    Validation:  0.46320593 - 0.9379883\n",
      "Test:  0.6627932 - 0.8764688 - Gini: 0.588\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 126 sample output: [0 0 1 1 0 0 0 0]\n",
      "[85.58 66.67 78.53 64.   78.57 62.07 64.71 70.  ]\n",
      "Training: 0.33094925 - 0.9916992    Validation:  0.46882638 - 0.93603516\n",
      "Test:  0.6741591 - 0.87859374 - Gini: 0.596\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 127 sample output: [1 0 0 0 0 0 1 0]\n",
      "[82.1  66.67 76.19 74.67 83.72 61.54 29.79 78.79]\n",
      "Training: 0.34794158 - 0.98291016    Validation:  0.5186167 - 0.9194336\n",
      "Test:  0.6663574 - 0.8595625 - Gini: 0.605\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 128 sample output: [1 0 0 0 0 0 0 0]\n",
      "[83.51 88.89 79.6  85.72 69.09 53.85 48.78 71.43]\n",
      "Training: 0.31840655 - 0.9951172    Validation:  0.43744498 - 0.9316406\n",
      "Test:  0.6605856 - 0.87284374 - Gini: 0.603\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 129 sample output: [0 0 0 1 0 0 0 0]\n",
      "[82.3  94.74 78.36 59.26 73.91 42.86 47.06 80.  ]\n",
      "Training: 0.33143023 - 0.9921875    Validation:  0.4839992 - 0.9277344\n",
      "Test:  0.66649497 - 0.87715626 - Gini: 0.602\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 130 sample output: [0 0 0 0 1 0 0 0]\n",
      "[80.   61.53 74.45 73.85 88.   66.67 64.52 63.64]\n",
      "Training: 0.33184162 - 0.9926758    Validation:  0.48094577 - 0.9291992\n",
      "Test:  0.6548337 - 0.87859374 - Gini: 0.596\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 131 sample output: [1 0 0 0 0 0 0 0]\n",
      "[87.78 75.   80.23 72.13 95.24 60.   71.8  66.67]\n",
      "Training: 0.339658 - 0.9868164    Validation:  0.44104382 - 0.94677734\n",
      "Test:  0.65219086 - 0.8788437 - Gini: 0.597\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 132 sample output: [1 0 0 0 0 0 0 0]\n",
      "[ 84.21  66.67  78.26  50.   100.    66.67  66.67 100.  ]\n",
      "Training: 0.32221353 - 0.9946289    Validation:  0.54225653 - 0.9391026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  0.6646267 - 0.87609375 - Gini: 0.601\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 133 sample output: [1 0 0 0 0 0 0 0]\n",
      "[92.59 46.15 86.21 77.97 80.95 70.   42.86 69.57]\n",
      "Training: 0.33832282 - 0.9941406    Validation:  0.47701824 - 0.94873047\n",
      "Test:  0.6642234 - 0.8790625 - Gini: 0.596\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 134 sample output: [1 0 0 0 0 0 0 0]\n",
      "[86.18 73.69 77.84 61.54 81.82 44.44 81.08 77.78]\n",
      "Training: 0.31151438 - 0.9975586    Validation:  0.44224826 - 0.94140625\n",
      "Test:  0.6652954 - 0.88075 - Gini: 0.594\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 135 sample output: [0 0 1 0 0 0 0 0]\n",
      "[87.14 66.67 78.66 73.08 84.62 73.33 54.55 72.73]\n",
      "Training: 0.3176066 - 0.9975586    Validation:  0.46663618 - 0.94140625\n",
      "Test:  0.6622164 - 0.879875 - Gini: 0.594\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 136 sample output: [1 0 0 0 0 0 0 0]\n",
      "[85.09 76.92 74.6  61.9  89.47 81.48 68.18 71.43]\n",
      "Training: 0.31941772 - 0.9970703    Validation:  0.4493327 - 0.9379883\n",
      "Test:  0.6593298 - 0.879625 - Gini: 0.595\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 137 sample output: [0 0 0 0 0 0 0 0]\n",
      "[83.25 76.92 77.89 77.61 84.45 41.38 59.46 88.24]\n",
      "Training: 0.33031476 - 0.9916992    Validation:  0.4535064 - 0.93359375\n",
      "Test:  0.66042066 - 0.88328123 - Gini: 0.593\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 138 sample output: [0 0 0 0 0 0 0 0]\n",
      "[85.19 73.68 81.52 65.52 71.43 64.29 74.42 93.75]\n",
      "Training: 0.34452635 - 0.99560547    Validation:  0.48921067 - 0.9404297\n",
      "Test:  0.6629422 - 0.88028127 - Gini: 0.595\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 139 sample output: [0 0 1 0 0 0 0 0]\n",
      "[83.81 80.   78.26 45.45 82.05 43.48 50.   91.43]\n",
      "Training: 0.32320267 - 0.99609375    Validation:  0.4872868 - 0.93115234\n",
      "Test:  0.65525275 - 0.880625 - Gini: 0.593\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 140 sample output: [1 0 0 0 0 0 0 0]\n",
      "[87.77 71.43 78.45 85.11 85.71 56.   76.19 97.14]\n",
      "Training: 0.35571957 - 0.9892578    Validation:  0.44490308 - 0.9482422\n",
      "Test:  0.66536623 - 0.88025 - Gini: 0.59\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 141 sample output: [1 0 0 0 0 0 0 0]\n",
      "[84.06 80.   74.07 76.67 84.   25.   59.26 88.  ]\n",
      "Training: 0.34205645 - 0.9941406    Validation:  0.49570936 - 0.9345703\n",
      "Test:  0.6678205 - 0.88140625 - Gini: 0.592\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 142 sample output: [0 0 1 0 0 0 1 0]\n",
      "[85.98 86.95 80.26 76.67 86.79 48.   55.81 96.3 ]\n",
      "Training: 0.32622907 - 0.9941406    Validation:  0.4597919 - 0.9428711\n",
      "Test:  0.66331214 - 0.8789375 - Gini: 0.59\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 143 sample output: [0 0 0 1 0 0 0 0]\n",
      "[84.21 90.91 84.44 85.19 82.92 60.   52.94 83.87]\n",
      "Training: 0.33658868 - 0.9951172    Validation:  0.4482258 - 0.9448242\n",
      "Test:  0.667026 - 0.8813437 - Gini: 0.591\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 144 sample output: [1 0 0 0 0 0 0 0]\n",
      "[87.2  88.89 81.93 80.56 83.33 63.64 61.11 69.57]\n",
      "Training: 0.33095655 - 0.9873047    Validation:  0.45190555 - 0.94628906\n",
      "Test:  0.6567339 - 0.88325 - Gini: 0.592\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 145 sample output: [0 0 1 1 0 0 0 0]\n",
      "[78.64 82.35 76.68 67.86 83.33 57.9  72.34 62.07]\n",
      "Training: 0.3381797 - 0.9926758    Validation:  0.51797837 - 0.9238281\n",
      "Test:  0.65279174 - 0.8847188 - Gini: 0.598\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 146 sample output: [0 1 0 0 0 0 0 0]\n",
      "[81.   84.61 76.24 69.84 58.82 42.42 42.1  80.  ]\n",
      "Training: 0.33184528 - 0.98828125    Validation:  0.5402796 - 0.9199219\n",
      "Test:  0.6609129 - 0.8716875 - Gini: 0.605\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 147 sample output: [0 0 1 0 0 0 1 0]\n",
      "[83.55 76.19 73.08 77.34 89.8  44.44 52.94 72.73]\n",
      "Training: 0.34711847 - 0.984375    Validation:  0.45769146 - 0.93115234\n",
      "Test:  0.6392623 - 0.87834376 - Gini: 0.616\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 148 sample output: [1 0 0 0 0 0 0 0]\n",
      "[ 80.      nan  77.42 100.    80.      nan  66.67 100.  ]\n",
      "Training: 0.31026858 - 0.99609375    Validation:  0.3931112 - 0.9423077\n",
      "Test:  0.6643056 - 0.8759062 - Gini: 0.613\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 149 sample output: [0 0 1 0 0 0 0 0]\n",
      "[ 83.08 100.    77.72  74.63  68.42  52.18  62.5   59.26]\n",
      "Training: 0.32316807 - 0.9970703    Validation:  0.4616094 - 0.9291992\n",
      "Test:  0.6585166 - 0.8779375 - Gini: 0.612\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 150 sample output: [0 0 0 0 0 0 0 0]\n",
      "[88.51 50.   83.43 82.35 90.   61.9  52.17 82.76]\n",
      "Training: 0.35417742 - 0.9916992    Validation:  0.48937094 - 0.9433594\n",
      "Test:  0.6631407 - 0.88203126 - Gini: 0.606\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 151 sample output: [1 0 0 0 0 0 0 0]\n",
      "[ 84.55 100.    75.58  82.35  86.37  48.28  75.87  91.67]\n",
      "Training: 0.31441242 - 0.99609375    Validation:  0.46960926 - 0.94140625\n",
      "Test:  0.6619144 - 0.8819063 - Gini: 0.606\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 152 sample output: [1 0 0 0 0 0 0 0]\n",
      "[88.46 78.57 81.72 81.63 93.33 50.   60.   91.43]\n",
      "Training: 0.3269537 - 0.9946289    Validation:  0.497599 - 0.9477539\n",
      "Test:  0.66107064 - 0.88096875 - Gini: 0.604\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 153 sample output: [0 0 1 0 0 0 0 0]\n",
      "[84.93 85.71 76.5  73.68 82.35 68.97 55.56 78.26]\n",
      "Training: 0.3235963 - 0.99658203    Validation:  0.45310432 - 0.9370117\n",
      "Test:  0.66194326 - 0.88246876 - Gini: 0.604\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154 sample output: [1 0 0 0 0 0 0 0]\n",
      "[86.88 60.   79.38 73.02 87.5  45.45 56.25 85.71]\n",
      "Training: 0.33943045 - 0.99121094    Validation:  0.44490552 - 0.93896484\n",
      "Test:  0.6578149 - 0.8842813 - Gini: 0.604\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 155 sample output: [1 0 0 0 0 0 0 0]\n",
      "[83.93 63.15 75.29 67.74 84.85 51.62 46.51 80.  ]\n",
      "Training: 0.36069015 - 0.98779297    Validation:  0.54080284 - 0.92578125\n",
      "Test:  0.6574226 - 0.88440627 - Gini: 0.603\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 156 sample output: [0 0 0 0 1 0 0 1]\n",
      "[84.06 69.56 77.71 77.92 76.19 43.48 65.12 87.5 ]\n",
      "Training: 0.3612246 - 0.9892578    Validation:  0.48285857 - 0.9355469\n",
      "Test:  0.6635995 - 0.88284373 - Gini: 0.602\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 157 sample output: [0 0 0 1 0 1 0 0]\n",
      "[91.53 75.   86.25 75.47 95.   38.46 56.25 81.82]\n",
      "Training: 0.3331812 - 0.9916992    Validation:  0.44186455 - 0.9536133\n",
      "Test:  0.65668607 - 0.884 - Gini: 0.602\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 158 sample output: [1 0 0 0 0 1 0 0]\n",
      "[86.1  95.24 84.02 73.53 92.31 66.67 44.44 81.25]\n",
      "Training: 0.32912326 - 0.99121094    Validation:  0.46230665 - 0.9458008\n",
      "Test:  0.65843433 - 0.88328123 - Gini: 0.602\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 159 sample output: [0 0 0 0 0 0 0 0]\n",
      "[83.55 62.5  80.93 78.57 77.42 23.52 71.11 91.67]\n",
      "Training: 0.3365529 - 0.99316406    Validation:  0.46029234 - 0.9399414\n",
      "Test:  0.6618918 - 0.88453126 - Gini: 0.601\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 160 sample output: [1 0 1 0 0 0 0 0]\n",
      "[83.49 75.   82.54 65.31 90.91 61.54 54.05 71.43]\n",
      "Training: 0.33958223 - 0.9951172    Validation:  0.4541927 - 0.9399414\n",
      "Test:  0.6611575 - 0.8829687 - Gini: 0.601\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 161 sample output: [0 0 1 0 0 0 0 0]\n",
      "[87.5  72.72 77.01 75.55 76.6  20.   75.55 75.  ]\n",
      "Training: 0.33845615 - 0.99316406    Validation:  0.46834522 - 0.94091797\n",
      "Test:  0.65974396 - 0.8838438 - Gini: 0.598\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 162 sample output: [0 0 1 0 0 1 0 0]\n",
      "[85.3  75.   80.41 85.   89.8  64.29 78.57 83.87]\n",
      "Training: 0.32378584 - 0.9946289    Validation:  0.44751257 - 0.94921875\n",
      "Test:  0.6583764 - 0.88425 - Gini: 0.599\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 163 sample output: [0 0 1 0 0 0 0 0]\n",
      "[85.84 87.5  71.05 77.19 80.85 70.   66.67 76.92]\n",
      "Training: 0.3309023 - 0.9980469    Validation:  0.45028043 - 0.9399414\n",
      "Test:  0.6641523 - 0.8825 - Gini: 0.597\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 164 sample output: [0 0 0 0 1 0 0 0]\n",
      "[ 91.43    nan  81.25  50.    80.   100.    33.33  66.67]\n",
      "Training: 0.32149932 - 0.9941406    Validation:  0.51032835 - 0.9391026\n",
      "Test:  0.66004956 - 0.8849375 - Gini: 0.599\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 165 sample output: [1 0 0 0 0 0 0 0]\n",
      "[88.67 61.54 80.44 69.09 93.03 50.   64.87 96.55]\n",
      "Training: 0.30993205 - 0.9926758    Validation:  0.46646056 - 0.94677734\n",
      "Test:  0.664631 - 0.8820625 - Gini: 0.598\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 166 sample output: [0 0 1 0 0 0 1 0]\n",
      "[85.33 81.82 75.74 70.42 70.97 58.07 63.64 78.26]\n",
      "Training: 0.32314014 - 0.9897461    Validation:  0.4871351 - 0.9243164\n",
      "Test:  0.6324488 - 0.87003124 - Gini: 0.62\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 167 sample output: [0 0 0 0 1 0 0 0]\n",
      "[87.18 71.43 77.59 59.09 76.93 51.85 63.63 45.16]\n",
      "Training: 0.31655437 - 0.9868164    Validation:  0.48343918 - 0.92626953\n",
      "Test:  0.6460114 - 0.8700625 - Gini: 0.621\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 168 sample output: [1 0 0 0 0 0 0 0]\n",
      "[82.11 44.44 75.   68.65 84.44 46.15 60.   70.  ]\n",
      "Training: 0.36152464 - 0.98339844    Validation:  0.44537002 - 0.921875\n",
      "Test:  0.6515152 - 0.8776875 - Gini: 0.619\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 169 sample output: [1 0 0 0 0 0 0 1]\n",
      "[85.18 82.35 84.54 65.52 66.67 45.16 64.86 63.16]\n",
      "Training: 0.34440768 - 0.9916992    Validation:  0.42549884 - 0.9321289\n",
      "Test:  0.6263044 - 0.88128126 - Gini: 0.619\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 170 sample output: [1 0 0 0 0 0 0 0]\n",
      "[85.45 77.78 80.95 79.25 84.44 60.87 60.   84.62]\n",
      "Training: 0.33194894 - 0.9916992    Validation:  0.45999685 - 0.94384766\n",
      "Test:  0.64834714 - 0.8825 - Gini: 0.614\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 171 sample output: [1 0 0 0 0 0 0 0]\n",
      "[84.27 87.5  82.63 76.93 94.44 58.07 73.33 72.  ]\n",
      "Training: 0.31764755 - 0.9941406    Validation:  0.4284169 - 0.9453125\n",
      "Test:  0.63478166 - 0.8798438 - Gini: 0.614\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 172 sample output: [1 0 0 0 0 0 0 0]\n",
      "[85.3  88.89 87.5  88.14 80.77 64.51 51.43 77.77]\n",
      "Training: 0.35622728 - 0.98876953    Validation:  0.45655364 - 0.9477539\n",
      "Test:  0.6558958 - 0.88128126 - Gini: 0.618\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 173 sample output: [0 0 1 0 0 0 0 0]\n",
      "[85.18 92.31 80.85 65.12 80.   53.34 61.54 85.72]\n",
      "Training: 0.32331657 - 0.9921875    Validation:  0.45499146 - 0.9394531\n",
      "Test:  0.65265954 - 0.884375 - Gini: 0.613\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 174 sample output: [1 0 0 0 0 0 0 1]\n",
      "[90.21 86.95 75.5  81.36 78.05 66.67 44.44 82.05]\n",
      "Training: 0.30900759 - 0.99560547    Validation:  0.50347626 - 0.94091797\n",
      "Test:  0.6552089 - 0.8830938 - Gini: 0.614\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 175 sample output: [0 0 0 0 0 0 0 0]\n",
      "[84.5  80.   76.53 78.26 80.   30.77 55.55 71.43]\n",
      "Training: 0.34132558 - 0.9970703    Validation:  0.4536808 - 0.9370117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  0.65518785 - 0.88421875 - Gini: 0.611\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 176 sample output: [1 0 0 0 0 0 0 0]\n",
      "[87.56 53.33 81.53 82.19 84.44 38.09 57.78 86.96]\n",
      "Training: 0.34372234 - 0.99072266    Validation:  0.49149555 - 0.9423828\n",
      "Test:  0.6543821 - 0.8861875 - Gini: 0.612\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 177 sample output: [1 0 0 0 0 0 0 0]\n",
      "[85.71 66.67 76.02 73.68 79.17 33.33 54.55 83.33]\n",
      "Training: 0.3302979 - 0.9946289    Validation:  0.51771307 - 0.93359375\n",
      "Test:  0.65963095 - 0.8845937 - Gini: 0.611\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 178 sample output: [0 0 1 0 0 1 0 0]\n",
      "[86.13 87.5  81.18 80.   83.64 72.   61.54 83.34]\n",
      "Training: 0.30568916 - 0.9975586    Validation:  0.45292038 - 0.9472656\n",
      "Test:  0.65806216 - 0.882375 - Gini: 0.609\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 179 sample output: [1 0 0 0 0 0 0 1]\n",
      "[83.03 66.67 77.02 87.67 83.72 57.14 63.16 84.62]\n",
      "Training: 0.32390997 - 0.9941406    Validation:  0.4518701 - 0.9399414\n",
      "Test:  0.65719765 - 0.88421875 - Gini: 0.611\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 180 sample output: [1 0 0 0 0 0 0 0]\n",
      "[ 85.72 100.    70.    75.    50.      nan  88.89  66.67]\n",
      "Training: 0.33789855 - 0.9946289    Validation:  0.5005135 - 0.9358974\n",
      "Test:  0.6544231 - 0.88584375 - Gini: 0.611\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 181 sample output: [1 0 0 0 0 1 0 0]\n",
      "[83.49 90.91 81.25 65.22 81.48 36.36 46.67 85.72]\n",
      "Training: 0.3269922 - 0.99658203    Validation:  0.43871325 - 0.9379883\n",
      "Test:  0.6598811 - 0.88378125 - Gini: 0.61\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 182 sample output: [0 0 1 0 0 0 1 0]\n",
      "[89.66 89.66 81.14 78.69 85.   22.22 66.67 87.5 ]\n",
      "Training: 0.33513042 - 0.9913793    Validation:  0.4327153 - 0.94970703\n",
      "Test:  0.651832 - 0.8854687 - Gini: 0.61\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 183 sample output: [1 0 0 0 0 0 0 0]\n",
      "[86.38 87.5  78.79 78.69 85.71 51.85 73.47 85.72]\n",
      "Training: 0.34094384 - 0.9926758    Validation:  0.47324824 - 0.94384766\n",
      "Test:  0.6585316 - 0.88478124 - Gini: 0.609\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 184 sample output: [0 0 1 0 0 0 0 0]\n",
      "[ 82.18 100.    70.86  68.75  85.71  50.    58.07  76.19]\n",
      "Training: 0.34852093 - 0.99365234    Validation:  0.4639253 - 0.9296875\n",
      "Test:  0.65418094 - 0.88615626 - Gini: 0.608\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 185 sample output: [1 0 0 0 0 0 0 0]\n",
      "[80.77 52.63 81.48 78.87 87.5  59.09 55.81 73.33]\n",
      "Training: 0.31217185 - 0.9946289    Validation:  0.52235895 - 0.9277344\n",
      "Test:  0.65705323 - 0.88278127 - Gini: 0.614\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 186 sample output: [1 0 0 0 0 0 0 0]\n",
      "[83.74 60.87 79.6  69.39 78.79 56.   58.06 92.31]\n",
      "Training: 0.31716734 - 0.99658203    Validation:  0.49409288 - 0.93603516\n",
      "Test:  0.6581831 - 0.88446873 - Gini: 0.614\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 187 sample output: [0 0 0 0 1 0 0 0]\n",
      "[87.79 71.43 74.71 76.   69.23 66.67 56.25 78.26]\n",
      "Training: 0.3320921 - 0.9921875    Validation:  0.44615287 - 0.93847656\n",
      "Test:  0.65127206 - 0.882375 - Gini: 0.618\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 188 sample output: [1 0 0 0 0 0 0 0]\n",
      "[88.48 57.14 83.25 66.66 82.61 58.82 71.11 87.5 ]\n",
      "Training: 0.35826012 - 0.984375    Validation:  0.48022106 - 0.94091797\n",
      "Test:  0.65488136 - 0.87925 - Gini: 0.623\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 189 sample output: [1 0 0 0 0 1 0 0]\n",
      "[82.47 75.   81.48 81.25 84.21 44.44 77.42 84.85]\n",
      "Training: 0.34118277 - 0.99316406    Validation:  0.43756545 - 0.9453125\n",
      "Test:  0.6509341 - 0.88484377 - Gini: 0.618\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 190 sample output: [1 0 0 0 0 0 0 0]\n",
      "[86.48 61.53 81.36 79.31 86.96 37.04 66.67 72.73]\n",
      "Training: 0.30771866 - 0.99902344    Validation:  0.45626903 - 0.94091797\n",
      "Test:  0.64506346 - 0.88171875 - Gini: 0.616\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 191 sample output: [1 0 0 0 0 1 0 0]\n",
      "[80.91 84.21 80.46 85.25 76.92 40.   70.59 82.35]\n",
      "Training: 0.34094793 - 0.9916992    Validation:  0.45680168 - 0.9375\n",
      "Test:  0.66570246 - 0.87909377 - Gini: 0.623\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 192 sample output: [1 0 0 0 0 0 0 0]\n",
      "[88.15 83.33 80.93 79.46 85.71 76.47 63.16 84.62]\n",
      "Training: 0.33979264 - 0.9916992    Validation:  0.44283992 - 0.9472656\n",
      "Test:  0.66399485 - 0.87659377 - Gini: 0.624\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 193 sample output: [1 0 0 0 0 0 0 0]\n",
      "[87.74 80.   79.52 78.43 81.25 50.   60.   95.65]\n",
      "Training: 0.322838 - 0.99121094    Validation:  0.44303277 - 0.9423828\n",
      "Test:  0.6527698 - 0.8843125 - Gini: 0.622\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 194 sample output: [1 0 0 0 0 0 0 0]\n",
      "[85.85 69.57 82.35 66.66 85.71 45.45 48.78 75.  ]\n",
      "Training: 0.3348601 - 0.9926758    Validation:  0.49934655 - 0.9355469\n",
      "Test:  0.6583059 - 0.8792812 - Gini: 0.623\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 195 sample output: [0 1 0 0 0 0 0 0]\n",
      "[87.07 81.25 76.83 68.   85.   30.   53.33 82.35]\n",
      "Training: 0.35024464 - 0.9926758    Validation:  0.53133535 - 0.93310547\n",
      "Test:  0.6798657 - 0.8766875 - Gini: 0.615\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 196 sample output: [0 1 0 0 0 0 1 0]\n",
      "[ 84.85  80.    81.48    nan  90.91    nan  33.33 100.  ]\n",
      "Training: 0.33463103 - 0.99365234    Validation:  0.38051897 - 0.94551283\n",
      "Test:  0.6690558 - 0.88 - Gini: 0.623\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 197 sample output: [1 0 0 0 0 0 0 0]\n",
      "[89.81 90.91 83.51 69.09 80.   57.14 62.22 73.33]\n",
      "Training: 0.3462968 - 0.99316406    Validation:  0.44178948 - 0.94433594\n",
      "Test:  0.6638685 - 0.8801875 - Gini: 0.618\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 198 sample output: [0 0 1 0 0 0 0 0]\n",
      "[85.98 60.   81.08 83.08 90.91 76.93 68.29 76.19]\n",
      "Training: 0.33489662 - 0.99365234    Validation:  0.4182994 - 0.9472656\n",
      "Test:  0.6579585 - 0.88215625 - Gini: 0.619\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n",
      "epoch 199 sample output: [0 0 0 1 0 0 0 0]\n",
      "[86.41 94.74 80.23 80.   78.95 34.78 71.43 82.35]\n",
      "Training: 0.3217107 - 0.9970703    Validation:  0.47549716 - 0.94433594\n",
      "Test:  0.6585673 - 0.88403124 - Gini: 0.617\n",
      "precision: [87.01 80.98 44.03 37.92 56.14  0.   52.23 73.66]\n",
      "recall: [68.55 81.42 56.4  39.95 71.74  0.   59.21 55.68]\n",
      "f1score: [76.68 81.2  49.45 38.91 62.99   nan 55.5  63.42]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "Allentropies = []\n",
    "Allaccuracies = []\n",
    "Allscaled_errs = []\n",
    "AllValaccuracies = []\n",
    "AllGinis = []\n",
    "LastSave = 0\n",
    "fL = getFlatLabel(fLabels)\n",
    "\n",
    "print('            Entropy    Accuracy')\n",
    "epochs = 200\n",
    "for i in range(epochs):\n",
    "    count = 0\n",
    "    xVal,yVal = val_it.next()\n",
    "    yVal = getRealLabel(yVal,realLabel)\n",
    "    yVal = getFlatLabel(yVal)\n",
    "    w,Valentro,ValentroD, ValWEntro,Valaccu,Valcomp,Valout = sess.run([weights,mean_cross_entropy,cross_entropies,weighted_cross_entropies,accuracy, comparison,output], feed_dict = {visual_in: xVal, labels: yVal})\n",
    "    print('epoch ' + str(i) + ' sample output: ' + str(Valout[0]))\n",
    "    p,r,valf1 = getOutStats(Valout,yVal)\n",
    "    print(valf1)\n",
    "    if i==0:\n",
    "        print('Validation:  '+str(Valentro)+ ' - '+str(Valaccu))\n",
    "        AllValaccuracies.append(Valaccu)\n",
    "    else:\n",
    "        print('Training: '+str(np.mean(entropies))+' - '+str(np.mean(accuracies))+\n",
    "          '    Validation:  '+str(Valentro)+ ' - '+str(Valaccu))\n",
    "    \n",
    "    Testentro, Testaccu,TestEnc = sess.run([mean_cross_entropy, accuracy, encoded_visual], feed_dict = {visual_in: obs, labels: fL})\n",
    "    print('Test:  '+str(Testentro)+ ' - '+str(Testaccu)+ ' - Gini: ' + str(np.round(gini(np.abs(TestEnc)),3)))\n",
    "    AllGinis.append(gini(np.abs(TestEnc)))\n",
    "    p,r,f1 = getOutStats(out,fL)\n",
    "    print('precision: '+str(p))\n",
    "    print('recall: '+str(r))\n",
    "    print('f1score: '+str(f1))\n",
    "    \n",
    "    if Valaccu > np.max(AllValaccuracies):\n",
    "        saver.save(sess, \"./Results/TowerTraining/Classifier/Model_flat_weighted/model.ckpt\")\n",
    "        print('saved model')\n",
    "        LastSave = i-1\n",
    "        \n",
    "    AllValaccuracies.append(Valaccu)\n",
    "    for batchX, batchy in train_it:\n",
    "        batchy = getRealLabel(batchy,realLabel)\n",
    "        batchy = getFlatLabel(batchy)\n",
    "        entropies = []\n",
    "        accuracies = []\n",
    "        entro, all_entro,accu,comp, _ = sess.run([mean_cross_entropy, weighted_cross_entropies,accuracy, comparison,training_step], feed_dict = {visual_in: batchX, labels: batchy})\n",
    "        entropies.append(entro)\n",
    "        accuracies.append(accu)\n",
    "        if count>126:\n",
    "            Allentropies.append(entropies)\n",
    "            Allaccuracies.append(accuracies)\n",
    "            break\n",
    "        count = count+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "### Plot Training Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T21:36:35.317108Z",
     "start_time": "2020-09-11T21:36:35.183490Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x271aba8e630>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Allaccuracies)\n",
    "plt.plot(AllValaccuracies)\n",
    "plt.plot(AllGinis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T21:36:37.852139Z",
     "start_time": "2020-09-11T21:36:37.840195Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"./Results/TowerTraining/Classifier/Model_flat_weighted_2/Accs.npy\",Allaccuracies)\n",
    "np.save(\"./Results/TowerTraining/Classifier/Model_flat_weighted_2/Entro.npy\",Allentropies)\n",
    "np.save(\"./Results/TowerTraining/Classifier/Model_flat_weighted_2/Err.npy\",Allscaled_errs)\n",
    "np.save(\"./Results/TowerTraining/Classifier/Model_flat_weighted_2/ValAcc.npy\",AllValaccuracies)\n",
    "np.save(\"./Results/TowerTraining/Classifier/Model_flat_weighted_2/Ginis.npy\",AllGinis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Test Run Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:46:38.412216Z",
     "start_time": "2020-09-11T08:46:28.560532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Results/TowerTraining/Classifier/Model_flat_weighted/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "saver.restore(sess, \"./Results/TowerTraining/Classifier/Model_flat_weighted/model.ckpt\")\n",
    "act,out,grad,HG = sess.run([hidden,output,gradients,hidden_grad], feed_dict = {visual_in: obs,labels: getFlatLabel(fLabels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T14:17:31.105841Z",
     "start_time": "2020-12-11T14:17:31.091874Z"
    }
   },
   "outputs": [],
   "source": [
    "accs = np.load(\"./Results/TowerTraining/Classifier/Model_flat_weighted/ValAcc.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:46:43.360882Z",
     "start_time": "2020-09-11T08:46:43.340934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Training: 88.128125\n"
     ]
    }
   ],
   "source": [
    "print('After Training: '+str(np.sum(out==getFlatLabel(fLabels))/(4000*8)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:46:47.337743Z",
     "start_time": "2020-09-11T08:46:47.320789Z"
    }
   },
   "outputs": [],
   "source": [
    "fL = getFlatLabel(fLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:46:50.968530Z",
     "start_time": "2020-09-11T08:46:50.743890Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vkakerbeck\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = plt.hist(np.array(out)+np.array(fL)/2, bins = [0,0.5,1,1.5,2])\n",
    "precision = np.round(np.array(c[0])[:,3]/(np.array(c[0])[:,3]+np.array(c[0])[:,2])*100,2)# If L is predicted it is correct X% of time\n",
    "recall = np.round(np.array(c[0])[:,3]/(np.array(c[0])[:,3]+np.array(c[0])[:,1])*100,2)# Correctly identifies X% of L\n",
    "f1score = np.round(2*(precision*recall/(precision+recall)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:47:20.922585Z",
     "start_time": "2020-09-11T08:47:20.915572Z"
    }
   },
   "outputs": [],
   "source": [
    "figurePath = './Results/TowerTraining/Figures/AgentRewardComparisonsAdaTH/ActivationPatternsNormx2No-01/'\n",
    "classifier_stats = np.load(figurePath+'classifier_stats.npy',allow_pickle='TRUE').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:47:21.783099Z",
     "start_time": "2020-09-11T08:47:21.777116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 82.09876543209876,\n",
       " 'Accuracies': array([87.407, 94.296, 86.148, 86.444, 93.259, 82.37 , 90.148]),\n",
       " 'Precisions': array([76.012, 88.106, 59.347, 65.581, 85.333, 56.977, 78.261]),\n",
       " 'Recalls': array([75.143, 80.   , 80.   , 56.4  , 76.8  , 19.6  , 64.8  ]),\n",
       " 'F1Scores': array([75.58, 83.86, 68.14, 60.64, 80.84, 29.17, 70.9 ])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-11T08:47:26.294200Z",
     "start_time": "2020-09-11T08:47:26.038217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.bar(np.linspace(-0.2,5.8,7),classifier_stats['Accuracies'],width=0.4)\n",
    "plt.bar(np.linspace(0.2,6.2,7),cflat_stats[:-1],width=0.4)\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar(np.linspace(-0.2,5.8,7),classifier_stats['F1Scores'],width=0.4)\n",
    "plt.bar(np.linspace(0.2,6.2,7),f1score[:-1],width=0.4)\n",
    "plt.legend(['branch classifier','flat classifier'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "227.85px",
    "left": "1230px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
